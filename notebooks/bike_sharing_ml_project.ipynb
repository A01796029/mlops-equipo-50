{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f788e2",
   "metadata": {},
   "source": [
    "### 1. IMPORTACIÓN DE LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9309b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761524a9",
   "metadata": {},
   "source": [
    "### 2. CARGA DE LOS DATOS (DE MOMENTO CONSIDERANDO UN .CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Carga un conjunto de datos desde una ruta de archivo CSV.\n",
    "\n",
    "    Esta función encapsula la lógica de lectura de datos con Pandas,\n",
    "    incluyendo un manejo básico de errores si el archivo no se encuentra.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo .csv que se va a cargar.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: Un DataFrame de Pandas con los datos cargados,\n",
    "        o None si ocurre un error (ej. archivo no encontrado).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Intenta leer el archivo CSV y lo carga en un DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Datos cargados exitosamente desde: {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        # Manejo de error si el archivo no existe en la ruta especificada\n",
    "        print(f\"Error: El archivo no fue encontrado en la ruta: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Manejo de otros posibles errores durante la carga\n",
    "        print(f\"Ocurrió un error inesperado al cargar el archivo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175ed98",
   "metadata": {},
   "source": [
    "### 3. DIAGNÓSTICO INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d824d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_overview(df: pd.DataFrame, df_name: str = \"DataFrame\") -> None:\n",
    "    \"\"\"\n",
    "    Imprime un resumen completo y diagnóstico de un DataFrame.\n",
    "\n",
    "    Incluye dimensiones, tipos de datos, estadísticas descriptivas,\n",
    "    conteo de duplicados y porcentaje de valores nulos.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame que se va a analizar.\n",
    "        df_name (str): Un nombre opcional para el DataFrame que se mostrará en los reportes.\n",
    "    \"\"\"\n",
    "    print(f\"\\n===============ANÁLISIS EXPLORATORIO RÁPIDO PARA: '{df_name}'===============\")\n",
    "\n",
    "    # 1. Dimensiones del DataFrame\n",
    "    print(f\"\\n**Dimensiones:** {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "\n",
    "    # 2. Tipos de datos y valores no nulos\n",
    "    print(\"\\n**Tipos de Datos y Valores No Nulos:**\")\n",
    "    df.info()\n",
    "\n",
    "    # 3. Estadísticas Descriptivas para variables numéricas\n",
    "    print(\"\\n**Estadísticas Descriptivas (Numéricas):**\")\n",
    "    # Usamos .T para transponer la tabla y hacerla más legible\n",
    "    print(df.describe().T)\n",
    "\n",
    "    # 4. Conteo de filas duplicadas\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\n**Filas Duplicadas:** {duplicates} filas duplicadas encontradas.\")\n",
    "\n",
    "    # 5. Porcentaje de Valores Nulos por columna\n",
    "    null_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "    null_info = null_percentage[null_percentage > 0].sort_values(ascending=False)\n",
    "    \n",
    "    if not null_info.empty:\n",
    "        print(\"\\n**Porcentaje de Valores Nulos (>0%):**\")\n",
    "        print(null_info)\n",
    "    else:\n",
    "        print(\"\\n**No se encontraron valores nulos.**\")\n",
    "    \n",
    "    print(\"\\nFin del análisis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c8d8e",
   "metadata": {},
   "source": [
    "### 4. LIMPIEZA DE LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afb0e9",
   "metadata": {},
   "source": [
    "##### Validación del esquema. Eliminación de columnas no identificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d0d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(df: pd.DataFrame, valid_columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina las columnas de un DataFrame que no están en una lista de columnas válidas.\n",
    "\n",
    "    Esta función es útil para asegurar que el DataFrame solo contenga las columnas\n",
    "    esperadas según el esquema definido.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame a limpiar.\n",
    "        valid_columns (list): Una lista de strings con los nombres de las\n",
    "                              columnas que deben permanecer.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nuevo DataFrame que solo contiene las columnas válidas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identifica las columnas actuales del DataFrame\n",
    "    current_columns = df.columns.tolist()\n",
    "    \n",
    "    # Encuentra las columnas que están en el DataFrame pero no en la lista de válidas\n",
    "    cols_to_drop = [col for col in current_columns if col not in valid_columns]\n",
    "\n",
    "    if cols_to_drop:\n",
    "        print(f\"\\nColumnas a eliminar: {cols_to_drop}\")\n",
    "        # Elimina las columnas identificadas y devuelve una copia del df modificado\n",
    "        df_cleaned = df.drop(columns=cols_to_drop)\n",
    "        print(\"Columnas innecesarias eliminadas.\")\n",
    "    else:\n",
    "        print(\"No se encontraron columnas innecesarias. El esquema es correcto.\")\n",
    "        df_cleaned = df.copy() # Devuelve una copia para mantener la consistencia\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603e467",
   "metadata": {},
   "source": [
    "##### Conversión del tipo correcto de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f3e0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_initial_data_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Corrige los tipos de datos de columnas específicas a numérico y fecha.\n",
    "    Las categóricas de momento igual se consideran como numéricas, para facilitar el manejo de inválidos.\n",
    "\n",
    "    Usa 'errors=coerce' para convertir valores no válidos en NaN,\n",
    "    facilitando su manejo posterior.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame a procesar.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nuevo DataFrame con los tipos de datos corregidos.\n",
    "    \"\"\"\n",
    "\n",
    "    df_corrected = df.copy()\n",
    "    print(\"\\nIniciando corrección de tipos de datos...\")\n",
    "\n",
    "    # Define los grupos de columnas\n",
    "    numeric_cols = ['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt',\n",
    "                    'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "    \n",
    "    # 1. Procesa columnas numéricas\n",
    "    for col in numeric_cols:\n",
    "        # Omite si la columna no existe (por si fue eliminada antes)\n",
    "        if col in df_corrected.columns:\n",
    "            df_corrected[col] = pd.to_numeric(df_corrected[col], errors='coerce')\n",
    "\n",
    "    # 2. Procesa columna de fecha\n",
    "    if 'dteday' in df_corrected.columns:\n",
    "        # Usamos format='mixed' para manejar explícitamente los formatos múltiples\n",
    "        df_corrected['dteday'] = pd.to_datetime(\n",
    "            df_corrected['dteday'], \n",
    "            errors='coerce', \n",
    "            format='mixed' # Esta es la solución\n",
    "        )\n",
    "        \n",
    "    print(\"Tipos de datos corregidos de forma semántica.\")\n",
    "    return df_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19660c0",
   "metadata": {},
   "source": [
    "##### Manejo de valores no válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b39495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_invalid_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Valida los datos contra un conjunto de reglas y convierte los inválidos a NaN.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame con tipos de datos ya corregidos.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nuevo DataFrame con los valores inválidos convertidos a NaN.\n",
    "    \"\"\"\n",
    "\n",
    "    df_validated = df.copy()\n",
    "    print(\"\\nIniciando validación de valores...\")\n",
    "\n",
    "    # Diccionario de reglas de validación\n",
    "    # Para categóricas: lista de valores permitidos\n",
    "    # Para numéricas: tupla con (valor_mínimo, valor_máximo)\n",
    "    validation_rules = {\n",
    "        'dteday': (pd.to_datetime('2011-01-01'), pd.to_datetime('2012-12-31')),\n",
    "        'season': [1, 2, 3, 4],\n",
    "        'yr': [0, 1],\n",
    "        'mnth': list(range(1, 13)),\n",
    "        'hr': list(range(0, 24)),\n",
    "        'holiday': [0, 1],\n",
    "        'weekday': list(range(0, 7)),\n",
    "        'workingday': [0, 1],\n",
    "        'weathersit': [1, 2, 3, 4],\n",
    "        'hum': (0.0, 1.0),\n",
    "        'windspeed': (0.0, 1.0),\n",
    "        'cnt': (0, float('inf')) # El conteo no puede ser negativo\n",
    "    }\n",
    "\n",
    "    for column, rule in validation_rules.items():\n",
    "        if column in df_validated.columns:\n",
    "            # Conteo inicial de nulos para reporte\n",
    "            initial_nulls = df_validated[column].isnull().sum()\n",
    "\n",
    "            # Validación para variables categóricas (regla es una lista)\n",
    "            if isinstance(rule, list):\n",
    "                invalid_mask = ~df_validated[column].isin(rule)\n",
    "            # Validación para variables numéricas (regla es una tupla)\n",
    "            elif isinstance(rule, tuple):\n",
    "                min_val, max_val = rule\n",
    "                invalid_mask = (df_validated[column] < min_val) | (df_validated[column] > max_val)\n",
    "            \n",
    "            # Reemplaza los valores que no cumplen la regla con NaN\n",
    "            df_validated.loc[invalid_mask, column] = np.nan\n",
    "            \n",
    "            # Reporta cuántos valores inválidos se encontraron y corrigieron\n",
    "            final_nulls = df_validated[column].isnull().sum()\n",
    "            newly_invalid = final_nulls - initial_nulls\n",
    "            if newly_invalid > 0:\n",
    "                print(f\"  -> Columna '{column}': {newly_invalid} valores inválidos convertidos a NaN.\")\n",
    "\n",
    "    print(\"Validación de valores completada.\")\n",
    "    return df_validated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
